{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ac38cf-10d4-48c4-b294-fb2b5775baae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238db16b-ac3a-4041-9ce1-10e1369365fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dataset(traffic, ic_master, search_spec, search_unspec):\n",
    "    # 欠損値の除外\n",
    "    traffic = traffic[traffic['speed'].isnull()==False]\n",
    "    ic_master.dropna(inplace=True)\n",
    "    search_spec.dropna(inplace=True)\n",
    "    search_unspec.dropna(inplace=True)\n",
    "    \n",
    "    # datetimeからdateを作成\n",
    "    traffic['date'] = traffic['datetime'].apply(lambda x: x.split()[0])\n",
    "\n",
    "    # データのマージ\n",
    "    traffic = traffic.merge(ic_master, on=['start_code', 'end_code'], how='left')\n",
    "    traffic = traffic.merge(search_spec, on=['datetime', 'start_code', 'end_code'], how='left')\n",
    "    traffic = traffic.merge(search_unspec, on=['date', 'start_code', 'end_code'], how='left')\n",
    "    traffic.sort_values(['date', 'start_code', 'end_code'], inplace=True)\n",
    "    traffic.reset_index(drop=True, inplace=True)\n",
    "    traffic.drop(columns='date', inplace=True)\n",
    "\n",
    "    # データ型の変更\n",
    "    traffic['datetime'] = pd.to_datetime(traffic['datetime'])\n",
    "\n",
    "    return traffic\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--exec-path', help = '/path/to/submit/src')\n",
    "    parser.add_argument('--data-dir', help = '/path/to/train')\n",
    "    parser.add_argument('--start-date', default = '2023-07-01', type = str, help='start date')\n",
    "    parser.add_argument('--end-date', default = '2023-07-31', type = str, help='end date')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def main():\n",
    "    # parse the arguments\n",
    "    args = parse_args()\n",
    "    exec_path = os.path.abspath(args.exec_path)\n",
    "    data_dir = os.path.abspath(args.data_dir)\n",
    "    start_date = args.start_date\n",
    "    end_date = args.end_date\n",
    "    print('\\nstart date: {}, end date:{}'.format(start_date, end_date))\n",
    "\n",
    "    # load the input data\n",
    "    print('\\nLoading Dataset...')\n",
    "    traffic = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "    search_spec = pd.read_csv(os.path.join(data_dir, 'search_specified.csv'))\n",
    "    search_unspec = pd.read_csv(os.path.join(data_dir, 'search_unspecified.csv'))\n",
    "    ic_master = pd.read_csv(os.path.join(data_dir, 'road_local.csv'))\n",
    "    log_pathes = glob.glob(f\"{data_dir}/search_raw_log/*.csv\")\n",
    "    \n",
    "    # 当日の検索数を使用できるように変更(search_spec, search_unspec)\n",
    "    search_spec['datetime'] = pd.to_datetime(search_spec['datetime'])\n",
    "    search_unspec['date'] = pd.to_datetime(search_unspec['date'])\n",
    "    search_spec['datetime'] -= pd.to_timedelta(1, 'd')\n",
    "    search_unspec['date'] -= pd.to_timedelta(1, 'd')\n",
    "    search_spec['datetime'] = search_spec['datetime'].astype('str')\n",
    "    search_unspec['date'] = search_unspec['date'].astype('str')\n",
    "\n",
    "    df = make_dataset(traffic, ic_master, search_spec, search_unspec)\n",
    "    df=df.drop(['start_name','end_name'],axis=1)\n",
    "    # 'direction'の値を0と1に置き換える\n",
    "    replace_dict = {'下り': 0, '上り': 1} # この辞書を編集して任意の変換ルールを定義\n",
    "    df['direction'] = df['direction'].replace(replace_dict)\n",
    "    train = df[df['datetime'] < start_date]\n",
    "    valid = df[(df['datetime']>=start_date+' 00:00:00') & (df['datetime']<=end_date+' 23:00:00')]\n",
    "    \n",
    "    #学習用のログデータの抽出\n",
    "    train_log_pathes = [path for path in log_pathes if path.split(\"/\")[-1][:-4].replace(\"_\", \"-\") < start_date]\n",
    "    print('Done')\n",
    "    \n",
    "    # change the working directory\n",
    "    os.chdir(exec_path)\n",
    "    cwd = os.getcwd()\n",
    "    print('\\nMoved to {}'.format(cwd))\n",
    "    model_path = os.path.join('..', 'model')\n",
    "    sys.path.append(cwd)\n",
    "\n",
    "    # load the model\n",
    "    from predictor import ScoringService\n",
    "    print('\\nLoading the model...', end = '\\r')\n",
    "    inference_log_data = ...\n",
    "    model_flag = ScoringService.get_model(model_path, train, inference_log_data)\n",
    "    if model_flag:\n",
    "        print('Loaded the model.')\n",
    "    else:\n",
    "        print('Could not load the model.')\n",
    "        return None\n",
    "    \n",
    "    print('-----------------')\n",
    "\n",
    "    predictions = pd.DataFrame()\n",
    "    for d, input_df in tqdm(valid.groupby(valid['datetime'].dt.date)):\n",
    "        \n",
    "        datetime_str = d.strftime('%Y/%m/%d').replace('/', '_')\n",
    "        input_log = pd.read_csv(f\"{data_dir}/search_raw_log/{datetime_str}.csv\")\n",
    "        prediction = ScoringService.predict(input_df, input_log)\n",
    "        \n",
    "\n",
    "\n",
    "        predictions = pd.concat([predictions, prediction])\n",
    "    \n",
    "    \n",
    "    print('the end')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265b911b-feb4-4439-b1e5-b9478c188de7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start date: 2023-07-01, end date:2023-07-30\n",
      "\n",
      "Loading Dataset...\n",
      "Done\n",
      "\n",
      "Moved to /home/work/trafic/run_test/sample_submit/src\n",
      "\n",
      "Loaded the model....\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:02<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the end\n"
     ]
    }
   ],
   "source": [
    "def setup_argv():\n",
    "    sys.argv = [\n",
    "        'run.py',\n",
    "        '--exec-path', '/home/work/trafic/run_test/sample_submit/src',\n",
    "        '--data-dir', '/home/work/trafic/run_test/train',\n",
    "        '--start-date', '2023-07-01',\n",
    "        '--end-date', '2023-07-30'\n",
    "    ]\n",
    "\n",
    "def test_main():\n",
    "    setup_argv()  # コマンドライン引数を設定\n",
    "    main()  # main関数を実行\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734babee-e553-4aa5-a181-55a3c1ffbc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
